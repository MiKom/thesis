\chapter{OpenCL heterogenous programming platform}
This chapter will describe OpenCL. A framework for writing applications that
harness computational capabilities of heterogeneous hardware environment on
which applications are run. Since the introduction of programmable pipeline
in GPUs\footnote{Graphics Processing Unit} an opportunity appeared to use
capabilities of these devices to offload highly parallel, computationally
intensive tasks from main CPU\footnote{Central Processing Unit}. OpenCL can also
expose dedicated hardware units designed to perform certain specialized tasks
like Digital Signal Processing.

OpenCL is used in programming project described in \autoref{chap:project}.
Metaballs and Marching Cubes algorithm are implemented with it. Marching Cubes
algorithm and its OpenCL implementation are described in detail in
\autoref{chap:marchingcubes}.
\section{Introduction}
This section is based on \cite{Kirk:2010:PMP:1841511} and
\cite{gaster2012heterogeneous}.

\subsection{Beginnings of programmable GPUs}

From early 1980s to late 1990s most graphic hardware was fixed--function.
I.e. dedicated graphics units exposed fixed set of functions that were
implemented in hardware or drivers. It wasn't possible to write custom program
that would be executed on the GPU.

As the complexity of fixed--function APIs expanded, hardware vendors implemented
them with general purpose processors that could run some limited instruction set
on many processors. This instruction set was used to implement graphics APIs
like OpenGL or DirectX.

In 2001 NVIDIA released GeForce 3 graphics card that exposed this internal
instruction set to users of OpenGL and DirectX APIs. ATI technologies followed
with Radeon 9700 that could also run programs supplied by the user on the GPU.
DirectX 8 and OpenGL introduced programmable vertex stage. With
DirectX 9 another programmable stage was introduced, the pixel (or fragment in
OpenGL terminology) shader. At this point, vertex and pixel shaders were
implemented via separate chips in the GPU. In 2005, with release of XBox 360
first unified architecture was introduced, on which vertex and fragment shaders
were run on the same processor.

Graphics processing, that these devices were build for is very well suited for
parallelization. Vertex shader stage takes list of vertices as its input and
maps them onto the screen optionally defining colour of the vertex. Each
vertex is processed independently making it possible to process many vertices
at the same time.

Pixel shader stage receives position of the point and returns final colour of
the pixel. This also is done independently for each pixel.

\subsubsection[Early attempts at GPGPU]{Early attempts at GPGPU\footnote{General Purpose GPU}}

With the unification of computational resources in the GPUs they started to
resemble highly parallel computers. Researchers noted this fact, and tried to
harness enormous parallel performance for workloads other than graphics.

GPUs of DirectX 9 era were still designed in graphics processing in mind.
Although there were programmable stages in the pipeline, types of input and
output parameters in each stage were severely limited. Moreover, the final
result was generated as a pixel buffer, so the programmer had to map outputs of
his algorithm to 2D screen space with pixel colour as output. Inputs to the
pixel shader stage had to be supplied by textures.

Even with these issues, researchers who managed to port their algorithms to
GPUs reported great performance benefits.

\subsubsection{CUDA}

When working on Tesla GPU architecture, engineers at NVIDIA realized the
potential in providing device's resources in easier way. Additional instructions
and functionalities were added to the device. Among them, read and write
operation with arbitrary offsets\footnote{Shaders could only write to predestined
places in memory, reserved for pixel output}, synchronization barriers for
groups of threads, atomic read/write operations. New parallel programming model
was developed that defined hierarchy of threads.

To expose all these features to programmers new C--like language was
created and named CUDA\footnote{Compute Unified Device Architecture}.

CUDA is capable of operating without any DirectX or OpenGL context. Device it's
run on doesn't even have to be connected to any display output. CUDA programs
are usually inlined in larger C or C++ programs and are called \emph{kernels}.
Special compiler called \emph{nvcc} is used to compile kernel code. For more
information about CUDA refer to official CUDA website\footnote{\url{http://www.nvidia.com/object/cuda_home_new.html}}.

\subsubsection{Inception of OpenCL}

On June 16th, 2008 Khronos Group announced formation of Compute Working Group (CWG)
that was tasked with establishing open standard for programming heterogeneous
CPU and GPU environments\footnote{\url{https://www.khronos.org/news/press/khronos\_launches\_heterogeneous\_computing\_initiative}}.
CWG consisted of many hardware and software vendors interested in
standardization of such API.

Compute Working Group adopted proposal of Apple Inc. that submitted programming
interface called Open Compute Language (OpenCL). Apple was already developing
OpenCL for quite some time to have it ready for its upcoming Mac OS X Snow
Leopard release.

On December 9th, 2008 final specification of OpenCL 1.0 was
released\footnote{\url{https://www.khronos.org/news/press/the\_khronos\_group\_releases\_opencl\_1.0\_specification}}.
Releases of conforming implementations from hardware vendors followed\footnote{http://www.khronos.org/conformance/adopters/conformant-products/\#opencl}.

\subsection{Specification}
OpenCL specification is maintained by the Khronos Group. It consists of C API
and Kernel language that is similar to C99. Khronos releases official C++
wrapper API\footnote{This wrapper API is used in programming project of this thesis}.

Unofficial bindings for various languages and frameworks also exist. Among others
\begin{itemize}
	\item PyOpencl\footnote{\url{http://mathema.tician.de/software/pyopencl}}
		for Python
	\item JOCL\footnote{\url{http://www.jocl.org/}} for Java.
	\item fortrancl\footnote{\url{http://code.google.com/p/fortrancl/}} for Fortran
	\item gocl\footnote{\url{https://github.com/elima/gocl}} wrapper for C
		applications based on GObject
	\item QtOpenCL\footnote{\url{http://doc.qt.digia.com/opencl-snapshot/index.html}}
		wrapper based on Qt library semantics.
\end{itemize}

\section{Logical abstraction of computational resources}

OpenCL aims to be API that lets hardware manufacturers expose various kinds of
devices to the programmers in a consistent and abstracted way. To fulfil this
requirement OpenGL defines logical hierarchy of computational resources.
Hardware vendors map real hardware to this abstraction in their implementations
of OpenCL.

OpenCL defines one processor (\emph{host}) that is coordinating execution of
OpenCL kernels on one or more \emph{devices}. Host, is executing functions from
C API portion of the specification. It's responsible for discovering available
devices, setting up contexts for them, allocating memory on host and devices,
queuing execution of kernels and initiating transfer of data between various
memories.

Diagram of this logical structure is presented in \autoref{fig:clhw}.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.7]{chapters/opencl/opencl_hwmodel.jpg}
	\end{center}
	\caption{Logical partitioning of hardware in OpenCL}
	\label{fig:clhw}
\end{figure}

\subsection{Platforms}

On the top of the hierarchy is \emph{Platform}. It is usually an implementation
of OpenCL by a single vendor. To query list of available platform in the system
function \texttt{clGetPlatformIds()} must be called twice. Once with parameter
\texttt{platforms} set to \texttt{NULL} to obtain number of platforms, and
second time, with \texttt{platform} parameter set to array that will fit
number of \texttt{cl\_platform\_id} structures equal or greater than the number
in argument \texttt{num\_platforms} retrieved on first invocation of this
function.

Note however, that OpenCL is usually loaded as a dynamic library provided by
vendor. These libraries will usually return only one platform.

To address this problem Khronos Group introduced \texttt{cl\_khr\_icd} extension
that depending on operating system, will look for list of installed OpenCL
ICDs or Installable Client Drivers in place specific for given OS. If
implementation supports this extension, new function \texttt{clIcdGetPlatformIDsKHR}
is available that will present to the user platforms from all vendors available
on the system. This extension also makes sure, that function calls with OpenCL
object created in certain platform will be routed to implementations in this
platform.

\subsection{Devices}

Platform, may contain one or more \emph{devices}. Devices are units that
actually execute the kernel code. Device may map for example to single GPU or
CPU.

For example, NVIDIA OpenCL implementation presents each GPU available in the
system as separate device. OpenCL from AMD besides presenting GPUs also presents
supported CPUs as devices.

Device is last entity in hierarchy that has its distinct API object. Further
elements cannot be operated on, and are just abstract concepts to which vendors
map their hardware.

These elements are \emph{compute units} which are comprised of \emph{processing
elements}. Devices can be queried for number of compute units they contain
through \texttt{clGetDeviceInfo()} function.

\subsubsection{Mapping physical devices to logical hierarchy}

Exact details of mapping is dependant on OpenCL vendor. Underlying architectures
of GPUs, CPUs and DSPs\footnote{Digital Singal Processors} can differ greatly
even within the same class of devices.

\section{Memory types}

\section{Execution model}
